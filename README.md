## The Way We Move

Let's play with canvas drawing and WebAudio API, see if something interesting might appear.
A first attempt to _Code like no one's watching_.

### What is this?

The starting idea was the produce a _drawing_ that _move_/_evolve_ according its spectator's environment.
Something like a painting that lives with the person looking at it.
For now, it's still a simple experiment with HTML5 [Canvas API](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API) and the [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API).
I'm thinking about using more inputs in the future, such as the gyroscope, camera, geolocation, etc.

### Live demo

You can give it a try at https://the-way-we-move.surge.sh/

### How does it look?

Here is a screenshot but you'd better click the link above the enjoy the _real_ experience :metal:

![The Way We Move â€” ](screenshots/twwm2.png?raw=true "Project's Screenshot")

### A few links

 - [Generative Art with Node.js and Canvas](https://mattdesl.svbtle.com/generative-art-with-nodejs-and-canvas) was a huge source of inspiration. Especially the sections about *Color Palettes* and *Color Contrast*
 - [ColourLovers.com API](http://www.colourlovers.com/api) : As mentionned in the blog post linked above, the colors palettes used the COLOURlovers community. Kudos!

### What about the name?

It's named after _The way we move_, a song and album by Langhorne Slim that I'm totally fond of at the moment.

